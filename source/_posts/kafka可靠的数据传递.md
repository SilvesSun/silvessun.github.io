---
title: kafka可靠的数据传递
date: 2018-12-03 14:21:51
tags:
- kafka原理
categories:
- 消息队列
---

![](http://blogsk.oss-us-west-1.aliyuncs.com/kafka.png)

## 可靠性保证

`ACID` 原子性, 一致性, 隔离性和持久性

- kafka 可以保证分区消息的顺序
- 只有当消息被写入分区的所有同步副本时, 它才被认为是 "已提交的"
- 只要还有一个副本时活跃的, 那么已经提交的数据就不会丢失
- 消费者只能读取已经提交的数据

## 复制

kafka 的复制机制和分区的多副本架构是kafka可靠性保证的核心

消息写入多个副本可以使kafka在发生崩溃时仍能保持消息的持久性

复制功能是kafka架构的核心, 它可以在个别节点失效时仍能保持kafka 的可用性和持久性

kafka使用主题来组织数据, 每个主题分为若干分区, 每个分区存在若干副本. 副本保存在 broker 上

副本分为 *首领副本* 和 *跟随者副本*. 

- 每个分区都有一个首领副本, 为了保证一致性, 所有生产者请求和消费者请求都会经过这个副本
- 跟随者副本不处理来自客户端的请求. 他们唯一的任务就是从首领那里复制消息, 保持与首领一致的状态.

首领需要弄清哪个跟随者的状态与自己是一致的. 跟随者为了与首领保持消息的同步, 向首领发送获取数据的请求. 请求消息里包含了跟随者想要获取消息的偏移量, 
而且这些偏移量是有序的

通过查看每个跟随者请求的最新偏移量, 首领就会知道每个跟随者复制的进度. 如果跟随者在10s内没有请求任何消息或者没有请求最新的消息, 那么跟随者就会被认为
是不同步的. 持续得到最新消息的副本被称为同步的副本. 在首领发生失效时, 只有同步的副本才有可能称为新的首领

除了当前首领外, 每个分区还有一个 *首选首领*. 创建主题时选定的首领就是首选首领. 

## 生产者可靠性
### 发送确认
- 1. acks=0 意味着如果生产者能够通过网络把消息发送出去, 就认为已经成功写入kafka
- 2. acks=1 首领收到消息并写入到分区数据文件时会返回确认或者错误响应
- 3. acks=all  和 min.insync,replicas 结合, 就可以确定在返回确认之前至少有多少个副本收到消息.

### 生产者的重试参数

如果 broker 返回的错误可以通过重试来解决, 那么生产者会自动处理这些错误

## 消费者可靠性
只有那些被提交到kafka的数据, 也就是那些已经被写入所有同步副本的数据, 对消费者是可用的, 这意味着消费者得到的消息已经具备了一致性

消费者需要记录哪些消息是已经读取过的, 哪些消息是没有读取的. 这是在读取消息时不丢失消息的关键

消费者会获取一批事件中的最大偏移量, 然后从这个最大偏移量开始读取另外一批事件. 这样保证了消费者总能以正确的顺序获取新数据

### 配置

- group.id 如果两个消费者有相同的 group.id, 并且订阅了同一个主题, 那么每个消费者会分到主题分区的一个子集
- auto.offset.reset 当没有偏移量可提交或者提交的偏移量在broker上不存在时消费者会做些什么
- enable.auto.commit  可以让消费者基于任务调度自动提交偏移量, 也可以在代码里手动提交偏移量
- auto.commit.interval.ms  确定自动提交的间隔时间